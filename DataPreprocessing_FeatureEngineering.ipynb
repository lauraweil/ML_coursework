{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2487-2223 Machine Learning Assignment 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (25 points) - Zestimate this House\n",
    "\n",
    "Purchasing a house is a very big decision for most of us. Companies such as Zillows collected tons of data regarding the listing and sold price of American houses and build the predictive model, named *Zestimate*. You are expected to build a model similar as Zestimate to predict house price in Boston. \n",
    "\n",
    "![zestimate](https://i0.wp.com/www.housesoldeasy.com/wp-content/uploads/Screen-Shot-2016-08-15-at-7.22.09-PM.png?resize=300%2C258&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lauraweil/Documents/Machine Learning/Ind_ass1'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded correctly.\n",
      "Features: X. Target variable (price): y.\n",
      "X shape:  (506, 13) y shape:  (506,)\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY - LOAD DATA ### \n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\" \n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]]) # FEATURES \n",
    "y = raw_df.values[1::2, 2] # TARGET VARIABLE\n",
    "assert X.shape[0] == y.shape[0], 'Mismatch in number of examples.'\n",
    "print('Data loaded correctly.')\n",
    "print('Features: X. Target variable (price): y.')\n",
    "print('X shape: ',X.shape, 'y shape: ', y.shape)\n",
    "### END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of columns\n",
    "raw_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2    3      4      5     6       7    8      9     10\n",
       "0    0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3\n",
       "1  396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "2    0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8\n",
       "3  396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   NaN\n",
       "4    0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head of dataframe\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating pandas dataframe with X and y array with column names\n",
    "data = np.hstack([X, y.reshape(-1, 1)])\n",
    "column_names = column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "df = pd.DataFrame(data, columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1 (5 points) \n",
    "Create train and test set, each contains 80% and 20% of the dataset, respectively, using *train_test_split* function in scikit-learn. Train a linear model on the train set and evaluate on the test set, report the training error and test error, respectively (as mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "seed = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size = 0.2, random_state = seed)\n",
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train set\n",
    "train_x = train_set.iloc[:,0:(len(train_set.columns)-1)] \n",
    "train_y = train_set.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training model on the train set \n",
    "model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "test_x = test_set.iloc[:,0:(len(test_set.columns)-1)] \n",
    "test_y = test_set.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply model to Training Set\n",
    "pred_train = model.predict(train_x)\n",
    "    \n",
    "# Apply model to Test Set\n",
    "pred_test = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute square error on train data\n",
    "error_train = round(mean_squared_error(train_y, pred_train),2)\n",
    "    \n",
    "# Compute square error on test data (unseen)\n",
    "error_test = round(mean_squared_error(test_y, pred_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 23.41 and the test error is 16.94\n"
     ]
    }
   ],
   "source": [
    "print(f\"The training error is {error_train} and the test error is {error_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2 (5 points)\n",
    "\n",
    "Perform a 10-fold cross-validation on the whole data set. Show the averaged mean sqaured error on both train and test set at each fold. Explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "#Lists with train and test MSEs respectively \n",
    "train_mse_list = []\n",
    "test_mse_list = []\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_index, test_index in folds.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #MSE training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_mse_list.append(train_mse)\n",
    "    \n",
    "    #MSE test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_mse_list.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train Error Simple</th>\n",
       "      <th>Test Error Simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.737590</td>\n",
       "      <td>14.995853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.852821</td>\n",
       "      <td>32.804525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22.523709</td>\n",
       "      <td>17.599677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21.777057</td>\n",
       "      <td>23.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.476103</td>\n",
       "      <td>35.152553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22.262544</td>\n",
       "      <td>19.155889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>21.696286</td>\n",
       "      <td>24.140705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>22.206383</td>\n",
       "      <td>19.547712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>22.188014</td>\n",
       "      <td>20.268154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>21.465364</td>\n",
       "      <td>26.608136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Train Error Simple  Test Error Simple\n",
       "0     1           22.737590          14.995853\n",
       "1     2           20.852821          32.804525\n",
       "2     3           22.523709          17.599677\n",
       "3     4           21.777057          23.368827\n",
       "4     5           20.476103          35.152553\n",
       "5     6           22.262544          19.155889\n",
       "6     7           21.696286          24.140705\n",
       "7     8           22.206383          19.547712\n",
       "8     9           22.188014          20.268154\n",
       "9    10           21.465364          26.608136"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Fold\": np.arange(1,11),\"Train Error Simple\": train_mse_list,\"Test Error Simple\":test_mse_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation Question 1.2**\n",
    "\n",
    "The train error is the MSE of the linear regression model on the train set, while the test error is the MSE on the test set. Hence, we can say that the train error measures in sample performance, whereas the test error measures out of sample performance of the model. Considering the table above, we can see that the test error is generally higher than the train error. This means that the model has a relatively good fit, but it is not very good at generalizing to new data (i.e. the test data). Moreover, the test error is quite variable across folds, ranging from as low as 14.99% to as high as 35.15%. This indicates that the performance of the model can vary depending on the specific portion of the data that is used for testing. As a consequence, it is likely that the model is too sensitive to the train data, and therefore overfits, leading to high test errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.3 (5 points) \n",
    " \n",
    "Add 2-degree squared polynomial features (with no interactions) and perform 10-fold cross-validation on the whole data set. Show the mean sqaured error on both train and test set at each fold. Explain your findings.\n",
    "\n",
    "Hint: you may use sklearn.preprocessing.PolynomialFeatures and check how it produces the polynomial features with/without interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.preprocessing.PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "\n",
    "# Create an empty array with the same shape as X\n",
    "X_squared = np.empty_like(X)\n",
    "\n",
    "# Iterate through each column (feature) and square it element-wise\n",
    "for i in range(X.shape[1]):\n",
    "    X_squared[:, i] = X[:, i] ** 2\n",
    "    \n",
    "X_poly_no_interaction = np.hstack((X, X_squared))\n",
    "polydf = np.hstack([X_poly_no_interaction, y.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_poly = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "#Lists with train and test MSEs respectively \n",
    "polytrain_mse_list = []\n",
    "polytest_mse_list = []\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "for train_index, test_index in folds_poly.split(X_poly_no_interaction):\n",
    "    X_train, X_test = X_poly_no_interaction[train_index], X_poly_no_interaction[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #Training the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #MSE training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    polytrain_mse_list.append(train_mse)\n",
    "    \n",
    "    #MSE test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    polytest_mse_list.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train Error Simple</th>\n",
       "      <th>Test Error Simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.737590</td>\n",
       "      <td>14.995853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.852821</td>\n",
       "      <td>32.804525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22.523709</td>\n",
       "      <td>17.599677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21.777057</td>\n",
       "      <td>23.368827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20.476103</td>\n",
       "      <td>35.152553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>22.262544</td>\n",
       "      <td>19.155889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>21.696286</td>\n",
       "      <td>24.140705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>22.206383</td>\n",
       "      <td>19.547712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>22.188014</td>\n",
       "      <td>20.268154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>21.465364</td>\n",
       "      <td>26.608136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Train Error Simple  Test Error Simple\n",
       "0     1           22.737590          14.995853\n",
       "1     2           20.852821          32.804525\n",
       "2     3           22.523709          17.599677\n",
       "3     4           21.777057          23.368827\n",
       "4     5           20.476103          35.152553\n",
       "5     6           22.262544          19.155889\n",
       "6     7           21.696286          24.140705\n",
       "7     8           22.206383          19.547712\n",
       "8     9           22.188014          20.268154\n",
       "9    10           21.465364          26.608136"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Fold\": np.arange(1,11),\"Train Error Simple\": train_mse_list,\"Test Error Simple\":test_mse_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Train Error Poly</th>\n",
       "      <th>Test Error Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15.006067</td>\n",
       "      <td>8.059258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13.758195</td>\n",
       "      <td>19.165389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14.685211</td>\n",
       "      <td>11.485820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14.219525</td>\n",
       "      <td>15.247364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12.329310</td>\n",
       "      <td>34.656785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>14.544648</td>\n",
       "      <td>14.055095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>14.579986</td>\n",
       "      <td>11.922458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>14.486820</td>\n",
       "      <td>12.533399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>14.503166</td>\n",
       "      <td>12.904961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>13.331417</td>\n",
       "      <td>23.815244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Train Error Poly  Test Error Poly\n",
       "0     1         15.006067         8.059258\n",
       "1     2         13.758195        19.165389\n",
       "2     3         14.685211        11.485820\n",
       "3     4         14.219525        15.247364\n",
       "4     5         12.329310        34.656785\n",
       "5     6         14.544648        14.055095\n",
       "6     7         14.579986        11.922458\n",
       "7     8         14.486820        12.533399\n",
       "8     9         14.503166        12.904961\n",
       "9    10         13.331417        23.815244"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Fold\": np.arange(1,11),\"Train Error Poly\": polytrain_mse_list,\"Test Error Poly\":polytest_mse_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation findings question 1.3**\n",
    "\n",
    "Comparing the table above to the table of the previous question, we can conclude that the quadratic regression model generally performs better than the simple linear regression model. Specifically, the train and test errors of the polynomial model are lower in (almost all of) the folds compared to the errors of the simple linear regression. This implies that the quadratic regression model seems to provide a better fit to the data which makes sense because the increased complexity (i.e. polynomial 2) allows to better capture the relationships between the features and target variable median price. In addition, the lower test errors imply that the quadratic model is better at generalizing to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.4 (10 points)\n",
    "\n",
    "Perform cross-validation using ridge regression and lasso regression on different feature combinations (linear features vs. polynomial features obtained earlier respectively. Explain which method works better in this case. Check the coefficients and explain the differences between ridge regression and lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing\n",
    "ridge = Ridge()\n",
    "lasso = Lasso(alpha=1.0, max_iter=10000)\n",
    "model_list = [ridge,lasso]\n",
    "degree_list = [X, X_poly_no_interaction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val using ridge and lasso with simple linear model\n",
    "for model in model_list:\n",
    "    \n",
    "    for x in range(2):\n",
    "        model.fit(degree_list[x],y)\n",
    "    \n",
    "        #10-fold cross-validation with MSE\n",
    "        test_scores = cross_val_score(model, degree_list[x], y, cv=10, scoring='neg_mean_squared_error')\n",
    "        \n",
    "        #Negate average of test errors \n",
    "        mean_test_error = -np.mean(test_scores)\n",
    "        if model == ridge and x == 0:\n",
    "            MSE_simple_ridge = mean_test_error\n",
    "            ridge_simple_coef = model.coef_\n",
    "        elif model == ridge and x==1:\n",
    "            MSE_poly_ridge = mean_test_error\n",
    "            ridge_poly_coef = model.coef_\n",
    "        elif model == lasso and x ==0:\n",
    "            MSE_simple_lasso = mean_test_error\n",
    "            lasso_simple_coef = model.coef_  \n",
    "        else:\n",
    "            MSE_poly_lasso = mean_test_error\n",
    "            lasso_poly_coef = model.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge MSE</th>\n",
       "      <th>Lasso MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>34.078246</td>\n",
       "      <td>34.464085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polynomial</th>\n",
       "      <td>26.942921</td>\n",
       "      <td>30.776932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ridge MSE  Lasso MSE\n",
       "simple      34.078246  34.464085\n",
       "polynomial  26.942921  30.776932"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_labels = [\"simple\",\"polynomial\"]\n",
    "df_compare = pd.DataFrame({\"Ridge MSE\": [MSE_simple_ridge,MSE_poly_ridge],\"Lasso MSE\": [MSE_simple_lasso,MSE_poly_lasso]},index=index_labels)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_labels2 = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with coefficients for Lasso and Ridge simple regression:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge simple</th>\n",
       "      <th>Lasso poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.104595</td>\n",
       "      <td>-0.063437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.047443</td>\n",
       "      <td>0.049165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.008805</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.552393</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-10.777015</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.854000</td>\n",
       "      <td>0.949811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.005415</td>\n",
       "      <td>0.020910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.372654</td>\n",
       "      <td>-0.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.290142</td>\n",
       "      <td>0.264206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.012912</td>\n",
       "      <td>-0.015212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.876074</td>\n",
       "      <td>-0.722966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.008247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.533343</td>\n",
       "      <td>-0.761115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ridge simple  Lasso poly\n",
       "CRIM        -0.104595   -0.063437\n",
       "ZN           0.047443    0.049165\n",
       "INDUS       -0.008805   -0.000000\n",
       "CHAS         2.552393    0.000000\n",
       "NOX        -10.777015   -0.000000\n",
       "RM           3.854000    0.949811\n",
       "AGE         -0.005415    0.020910\n",
       "DIS         -1.372654   -0.668790\n",
       "RAD          0.290142    0.264206\n",
       "TAX         -0.012912   -0.015212\n",
       "PTRATIO     -0.876074   -0.722966\n",
       "B            0.009673    0.008247\n",
       "LSTAT       -0.533343   -0.761115"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table with coefficients for Lasso and Ridge simple regression:\")\n",
    "print(\"\")\n",
    "pd.DataFrame({\"Ridge simple\":ridge_simple_coef,\"Lasso poly\": lasso_simple_coef},index=index_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_labels3 = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','CRIM2','ZN2','INDUS2','CHAS2', 'NOX2','RM2','AGE2','DIS2','RAD2','TAX2','PTRATIO2','B2','LSTAT2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with coefficients for Lasso and Ridge polynomial regression:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge Poly</th>\n",
       "      <th>Lasso Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.351257</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.054308</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.166512</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.275836</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-6.403079</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-12.792450</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.015272</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-2.343501</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.615301</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.028830</td>\n",
       "      <td>-0.030181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-4.061011</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.033887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-1.434549</td>\n",
       "      <td>-1.302793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM2</th>\n",
       "      <td>0.002743</td>\n",
       "      <td>-0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN2</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS2</th>\n",
       "      <td>0.006537</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS2</th>\n",
       "      <td>1.275836</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX2</th>\n",
       "      <td>-8.490605</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM2</th>\n",
       "      <td>1.250163</td>\n",
       "      <td>0.316487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE2</th>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS2</th>\n",
       "      <td>0.120670</td>\n",
       "      <td>-0.064197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD2</th>\n",
       "      <td>-0.010358</td>\n",
       "      <td>0.003903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX2</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO2</th>\n",
       "      <td>0.093096</td>\n",
       "      <td>-0.020346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT2</th>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.022086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ridge Poly  Lasso Poly\n",
       "CRIM       -0.351257   -0.000000\n",
       "ZN         -0.054308   -0.000000\n",
       "INDUS      -0.166512   -0.000000\n",
       "CHAS        1.275836    0.000000\n",
       "NOX        -6.403079   -0.000000\n",
       "RM        -12.792450   -0.000000\n",
       "AGE        -0.015272    0.000000\n",
       "DIS        -2.343501   -0.000000\n",
       "RAD         0.615301    0.000000\n",
       "TAX        -0.028830   -0.030181\n",
       "PTRATIO    -4.061011   -0.000000\n",
       "B           0.026182    0.033887\n",
       "LSTAT      -1.434549   -1.302793\n",
       "CRIM2       0.002743   -0.001376\n",
       "ZN2         0.000736    0.000325\n",
       "INDUS2      0.006537   -0.000000\n",
       "CHAS2       1.275836    0.000000\n",
       "NOX2       -8.490605   -0.000000\n",
       "RM2         1.250163    0.316487\n",
       "AGE2        0.000123    0.000109\n",
       "DIS2        0.120670   -0.064197\n",
       "RAD2       -0.010358    0.003903\n",
       "TAX2        0.000020    0.000025\n",
       "PTRATIO2    0.093096   -0.020346\n",
       "B2         -0.000044   -0.000053\n",
       "LSTAT2      0.026027    0.022086"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table with coefficients for Lasso and Ridge polynomial regression:\")\n",
    "print(\"\")\n",
    "poly_coefs = pd.DataFrame({\"Ridge Poly\":ridge_poly_coef,\"Lasso Poly\": lasso_poly_coef},index=index_labels3)\n",
    "poly_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation question 1.4**\n",
    "\n",
    "Ridge and Lasso regularization are used to prevent overfitting. Specifically, in both Ridge and Lasso regression a penalty is added to the cost function, reducing the effect of some features on the model’s predicted values. In Ridge regression, the value of coefficients shrink as Lambda (regularization parameter) increases. Ridge regularization results in relatively small but nonzero coeffficients.\n",
    "\n",
    "On the other hand, Lasso regression pushes certain weights to be exactly 0. Crucially, this type of regularization tends to completely eliminate the coefficients of the least important features (i.e., set them to zero). In other words, Lasso regression creates a subset of features and returns only a few nonzero weights. \n",
    "\n",
    "The difference between Lasso and Ridge regression can be seen in the tables above. Whereas all features are assigned weights in Ridge regression, only a few features have non-zero weights in Lasso regression for both the simple and polynomial models.\n",
    "\n",
    "With respect to the model performance, following the MSE, Ridge regression performs slightly better than Lasso regression for the simple models; Ridge regression has an MSE of 34.078246 and Lasso regression has an MSE of 35.037835.The same goes for the quadratic models: Ridge regression has an MSE of 26.942921 compared to an MSE of 30.748620 for Lasso regression. \n",
    "\n",
    "Conclusively, Ridge regression outperforms Lasso regression in all model combinations. This might be due to the fact that the Lasso regression is too constraining and therefore results in high bias. The model with the lowest MSE (26) and therefore the best model is Ridge regression wiht polynomials. In addition, following lower MSEs, adding polynomial features improves the performance of both Ridge and Lasso regression models when compared to using simple linear features. This is likely because the polynomial features increase the complexity, and therefore the fit of the model, resulting in lower bias and increased accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (25 points) - Cancer Detection\n",
    "\n",
    "Given a dataset with features that are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass, which describes characteristics of the cell nuclei present in the image, let's try to predict whether the patients are diagnosed as Malignant (M) or Benign (B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\"\"\"\n",
    "DOCS:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer\n",
    "\"\"\"\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## number of rows\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1 (5 points) \n",
    "Use logistic regression to train the dataset through cross-validation, report the score on train and test set, respectively. Explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated train set score: 0.9583\n",
      "Cross-validated test set score: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    log_reg = LogisticRegression(random_state=42, max_iter=5000)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Accuracy on the training set\n",
    "    y_train_pred = log_reg.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # Accuracy on the test set\n",
    "    y_test_pred = log_reg.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "# Calculate the average accuracy across all folds for train and test sets\n",
    "train_cv_score = np.mean(train_acc_list)\n",
    "test_cv_score = np.mean(test_acc_list)\n",
    "print(f\"Cross-validated train set score: {train_cv_score:.4f}\")\n",
    "print(f\"Cross-validated test set score: {test_cv_score:.4f}\")\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "final_log_reg = LogisticRegression(random_state=42, max_iter=5000)\n",
    "final_log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation findings question 2.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy score of 0.9583 on the cross-validated training set indicates that the logistic regression model is able to correctly classify approximately 95.83% of the training samples on average across the 10 folds. Similarly, a test set score of 0.9600 shows that the model can correctly classify approximately 96.00% of the test samples on average across the 10 folds.\n",
    "\n",
    "Crucially, significantly high accuracy are assoicated with risk of overfitting (especially when there are many feature variables). Namely, high accuracy scores might imply that the model is too adjusted to the training set and therefore has a high chance of error due to variance. However, following the proximity of the train and test error, it can be concluded that the model also performs well on out of sample data, and is therefore not overfitting. Consequently, the model should be able to generalize well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.2 (5 points) \n",
    "By default, sklearn's logistic regression uses the L2 regularization. Now use the logistic regression without any regularzation to perform cross validation, report what do you find on train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated train set score: 0.9890\n",
      "Cross-validated test set score: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, penalty='none', random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    log_reg = LogisticRegression(random_state=42, max_iter=10000,penalty='none')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Accuracy on the training set\n",
    "    y_train_pred = log_reg.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # Accuracy on the test set\n",
    "    y_test_pred = log_reg.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_acc_list.append(test_acc)\n",
    "\n",
    "# Calculate the average accuracy across all folds for train and test sets\n",
    "train_cv_score = np.mean(train_acc_list)\n",
    "test_cv_score = np.mean(test_acc_list)\n",
    "print(f\"Cross-validated train set score: {train_cv_score:.4f}\")\n",
    "print(f\"Cross-validated test set score: {test_cv_score:.4f}\")\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "final_log_reg = LogisticRegression(random_state=42, max_iter=10000,penalty='none')\n",
    "final_log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation findings question 2.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the cross validated train test score and cross validated test set score are both higher compared to train and test scores generated in the previous question (Logisitc regression with L2 regularization). Given L2 regularization penalizes complex models, hereby decreasing fit and incrasing bias, it was expected that the cross validated train score for Logistic Regression with L2 regularization was lower (because the model is less sensitive to training data). \n",
    "\n",
    "Following this hypothesis, it was also hypothesized that the L2 with regularization would generate higher test scores (i.e., better able to generalize to new data) because it is less prone to overfitting. However, the test set score is also higher for the logistic regression without regularization, suggesting that this model is better at generalizing to new data. A significantly high test score for the logistic regression without L2 regularization might be caused by various factors including (but not limited to) high multicollinearity between features, low degree of complexity in dataset, and low degree of noise and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.3 (15 points) \n",
    "Check how many Benign and Malignant cases in the dataset. What might be the problem if we use the default score of the logistic regression cross-validation? Now adjust the class weight of M and L and retrain the model again to bias toward Malignant, using the relative weight of M and L as 2:1. What about the relaive weight to be 5:1, or 10:1? Explain what you find.\n",
    "\n",
    "Hint: you can use LogisticRegressionCV to combine LogisticRegression and cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Benighn cases in the dataset is 212.\n",
      "The number of Malignant cases in the dataset is 357.\n"
     ]
    }
   ],
   "source": [
    "# number of Benign cases in dataset\n",
    "benign = 0\n",
    "for x in y:\n",
    "    if x == 0:\n",
    "        benign += 1\n",
    "\n",
    "# number of Malignant cases in the dataset\n",
    "malignant = 0 \n",
    "\n",
    "for x in y:\n",
    "    if x == 1:\n",
    "        malignant += 1\n",
    "\n",
    "print(f\"The number of Benighn cases in the dataset is {benign}.\")\n",
    "print(f\"The number of Malignant cases in the dataset is {malignant}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of breast cancer detection the cost of false negatives is significantly high (labeling a malignant case as benign could have serious consequences for the patient). Therefore, the problem when using the default score of logisitc regression cross-validation is that the default score of logistic regression cross-validation may lead to a model that prioritizes overall accuracy at the expense of high false negative rates for the Malignant class. This is because the default scoring metric for binary classification in scikit-learn is accuracy, which places equal weight on both true positives and true negatives. Hence, in the context of breast cancer detection we need to adjust the model in such a way that it factors in the high cost of misclassifying true (malignant) values as false (benign)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Updated model with weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight ratio: 1\n",
      "Cross-validated train set score: 0.9510\n",
      "Cross-validated test set score: 0.9800\n",
      "Weight ratio: 2\n",
      "Cross-validated train set score: 0.9454\n",
      "Cross-validated test set score: 1.0000\n",
      "Weight ratio: 5\n",
      "Cross-validated train set score: 0.9463\n",
      "Cross-validated test set score: 1.0000\n",
      "Weight ratio: 10\n",
      "Cross-validated train set score: 0.9410\n",
      "Cross-validated test set score: 0.9600\n"
     ]
    }
   ],
   "source": [
    "# Define class weight ratios to try\n",
    "weight_ratios = [1, 2, 5, 10]\n",
    "\n",
    "for weight_ratio in weight_ratios:\n",
    "    # Set class weights based on weight ratio\n",
    "    class_weight = {0: 1, 1: weight_ratio}\n",
    "\n",
    "    # Define logistic regression model with cross-validation and class weights\n",
    "    log_reg = LogisticRegressionCV(random_state=42, max_iter=10000, cv=10, class_weight=class_weight)\n",
    "\n",
    "    # Train the model on the data\n",
    "    log_reg.fit(X, y)\n",
    "\n",
    "    # Print the accuracy score for the model\n",
    "    print(f\"Weight ratio: {weight_ratio}\")\n",
    "    print(f\"Cross-validated train set score: {log_reg.scores_[1].mean():.4f}\")\n",
    "    print(f\"Cross-validated test set score: {log_reg.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation findings question 2.3**\n",
    "\n",
    "Weight ratio: 1\n",
    "This is the case when both classes have equal weights. The train set score is 0.9510, and the test set score is 0.9800. This means that the model's average accuracy is 95.10% on the train set and 98% on the test set across all cross-validation folds.\n",
    "\n",
    "Weight ratio: 2\n",
    "In this case, the minority class has twice the weight of the majority class. The train set score is 0.9454, and the test set score is 1.0000. The train set score slightly decreased compared to the weight ratio of 1, but the test set score increased to 100%. This might indicate that the model is slightly better at generalizing to unseen data when the minority class is given more importance.\n",
    "\n",
    "Weight ratio: 5\n",
    "With a weight ratio of 5, the minority class is now given five times more weight than the majority class. The train set score is 0.9463, and the test set score is 1.0000. Similar to the weight ratio of 2, the train set score is slightly lower than the equal weight case, but the test set score remains at 100%. This suggests that further increasing the importance of the minority class doesn't seem to improve the model's performance on the test set.\n",
    "\n",
    "Weight ratio: 10\n",
    "The minority class is given ten times more weight than the majority class. The train set score is 0.9410, and the test set score is 0.9600. In this case, both the train and test set scores have decreased compared to the previous weight ratios. This could indicate that the model is now overemphasizing the minority class, leading to reduced overall performance.\n",
    "\n",
    "In summary, your results show that giving more weight to the minority class can improve the model's performance on the test set, but only up to a certain point. In this case, weight ratios of 2 and 5 yielded the best test set scores. However, further increasing the weight of the minority class (i.e., a weight ratio of 10) led to reduced performance on both the train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (50 points) - Call Me Maybe? \n",
    "\n",
    "\n",
    "\n",
    "![telemarketing](https://neilpatel.com/wp-content/uploads/2019/08/profissional-de-telemarketing-sorridente.jpeg)\n",
    "\n",
    "Telemarketing is a method of direct marketing in which a salesperson solicits prospective customers to buy products or services over the phone. It has become one of the most widely used marketing campaign methods to engage with customers with product and service opportunity. We have collected real data from a Portuguese retail bank, from May 2008 to June 2013 with thousands of phone contacts. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The current practice of many data teams is to build such propensity models and predict customer's probability to adopt the product and target them from the highest probability to the lowest probability. Note that telemarketing may incur some costs for contacting the customer, thus the success (i.e., the generated profit) of using machine learning model requries further inspection.  As the data scientist, you are asked to build a propensity model to evaluate the effectiveness of their telemarketing campaigns, i.e. whether the customer subscribed to the term deposit.  \n",
    "\n",
    "**Telemarketing Dataset (bank.csv)**\n",
    "All customers are contained in the file bank.csv. Each line of this file after the header row represents one customer of the Portuguese bank, and has the following format:\n",
    "\n",
    "### bank client data:\n",
    "- age (numeric)\n",
    "- job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "- marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "- education (categorical: 'primary', 'secondary', 'tertiary')\n",
    "- balance: amcount of bank account balance\n",
    "- default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "- housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "- loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "### related with the last contact of the current campaign:\n",
    "- contact: contact communication type (categorical: 'cellular','telephone', 'unknown')\n",
    "- day: last contact day of month\n",
    "- month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "- duration: last contact duration, in seconds (numeric). **Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed.**\n",
    "\n",
    "### other attributes:\n",
    "- campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "- pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; -1 means client was not previously contacted)\n",
    "- previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "- poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "- y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n",
    "\n",
    "Answer the following questions using the provided dataset. You can write down intermediate results towards the final answers. If any model invovles random_state, set it to be 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv('bank.csv', sep=';')\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "      <td>4521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.170095</td>\n",
       "      <td>1422.657819</td>\n",
       "      <td>15.915284</td>\n",
       "      <td>263.961292</td>\n",
       "      <td>2.793630</td>\n",
       "      <td>39.766645</td>\n",
       "      <td>0.542579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.576211</td>\n",
       "      <td>3009.638142</td>\n",
       "      <td>8.247667</td>\n",
       "      <td>259.856633</td>\n",
       "      <td>3.109807</td>\n",
       "      <td>100.121124</td>\n",
       "      <td>1.693562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>-3313.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>444.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>71188.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3025.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       balance          day     duration     campaign  \\\n",
       "count  4521.000000   4521.000000  4521.000000  4521.000000  4521.000000   \n",
       "mean     41.170095   1422.657819    15.915284   263.961292     2.793630   \n",
       "std      10.576211   3009.638142     8.247667   259.856633     3.109807   \n",
       "min      19.000000  -3313.000000     1.000000     4.000000     1.000000   \n",
       "25%      33.000000     69.000000     9.000000   104.000000     1.000000   \n",
       "50%      39.000000    444.000000    16.000000   185.000000     2.000000   \n",
       "75%      49.000000   1480.000000    21.000000   329.000000     3.000000   \n",
       "max      87.000000  71188.000000    31.000000  3025.000000    50.000000   \n",
       "\n",
       "             pdays     previous  \n",
       "count  4521.000000  4521.000000  \n",
       "mean     39.766645     0.542579  \n",
       "std     100.121124     1.693562  \n",
       "min      -1.000000     0.000000  \n",
       "25%      -1.000000     0.000000  \n",
       "50%      -1.000000     0.000000  \n",
       "75%      -1.000000     0.000000  \n",
       "max     871.000000    25.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     4000\n",
       "yes     521\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 (15 points)\n",
    "\n",
    "Split the data into 80% training set and 20% test set. **Build a pipeline to preprocess the indicated numerical features and categorical features separately**. For numerical features 'balance', 'campaign', standardize these features. For categorical features 'job', 'marital', 'education', 'default', transform them through one-hot encoding. For the numeric feature 'age', convert it into the quartile categorical variable and transform it through one-hot encoding. \n",
    "\n",
    "Train a Logistic regression model with L2 regularization using 5-fold cross validation (default hyperparameter) on the train set and show the accuracy, precision, recall on the train set. Explain whether the model is useful for the bank to identify the customer propensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(bank, test_size=0.2, random_state=42)\n",
    "\n",
    "bank_train = train_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "bank.hist(bins=50, figsize=(20,15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nan values\n",
    "sample_incomplete_rows = bank[bank.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "class AgeToQuartileTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, age_col='age'):\n",
    "        self.age_col = age_col\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        age_quartiles = pd.cut(X[self.age_col], bins=np.percentile(X[self.age_col], [0, 25, 50, 75, 100]), include_lowest=True, labels=False)\n",
    "        return age_quartiles.to_frame()\n",
    "\n",
    "def get_preprocessor(num_attribs, cat_attribs, age_col='age'):\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "    age_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector([age_col])),\n",
    "        ('age_to_quartile', AgeToQuartileTransformer(age_col)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_attribs),\n",
    "        ('cat', cat_pipeline, cat_attribs),\n",
    "        ('age', age_pipeline, [age_col]),\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining attributes \n",
    "cat_attribs = [\"job\", \"marital\", \"education\", \"default\"]\n",
    "num_attribs = [\"balance\",\"campaign\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = get_preprocessor(num_attribs,cat_attribs,age_col=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_prepared = preprocessor.fit_transform(bank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3616, 27)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4521, 7)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank[[\"balance\",\"campaign\",\"job\",\"marital\",\"education\",\"default\",\"age\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Logistic Regression Model and Performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8830199115044248.\n",
      "Recall is 0.0.\n",
      "Precision is 1.0.\n"
     ]
    }
   ],
   "source": [
    "# define target variable\n",
    "y = bank_train[\"y\"]\n",
    "\n",
    "log_reg_cv = LogisticRegressionCV(random_state=42, solver='lbfgs', max_iter=1000, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg_cv.fit(banking_prepared,y)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = log_reg_cv.predict(banking_prepared)\n",
    "\n",
    "#Calculate the precision score and avoid the warning message\n",
    "precision = precision_score(y, y_pred, pos_label=\"yes\",zero_division=1)\n",
    "recall = recall_score(y, y_pred, pos_label='yes')\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "print(f\"Accuracy is {accuracy}.\")\n",
    "print(f\"Recall is {recall}.\")\n",
    "print(f\"Precision is {precision}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation findings question 3.1**\n",
    "\n",
    "To determine if the model is useful for the bank to identify customer propensity, performance metrics including accuracy, recall, and precision need to be considered. At first sight, accuracy of 0.8830, meaning the proporiton of correct predicitions of the total predictions. Overall the model makes true predictions in about 80% of the cases. Secondly, a precision score of 1 means that the model is always correct when it predicts that a customer will subscribe. However, the recall (i.e. the proportion of true positive predictions out of the total actual positive cases) of 0.0 indicates that the model is not able to identify any customers who will subcribe to the deposit. Therefore, the precision score of 1 is likey due to the fact that the model does not make any positive predictions at all.\n",
    "\n",
    "Based on these performance metrics, the model is not useful for the bank to identify customers who will make a deposit. The recall of 0.0 indicates that the model is not able to identify any customers who will acquire the product, even though it has high precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 (10 points)\n",
    "\n",
    "Now add more features to the model to see if we can improve the performance (categorical features: 'housing', 'loan' and numerical features: 'day', 'duration'). Use the preprocess pipeline built previously to transform the data. Train a Logistic regression model with L1 regularization using 5-fold cross validation on the train set, by fine-tuning the hyperparameter alpha, i.e. the regularization strength from [0.001, 0.01, 0.1, 1]. Choose the correct score function that **reflect the current data team's practice**. Report the average score with the best hyperparameter. **Does model performance improve, and if so, how?**\n",
    "\n",
    "**Expalin whether all features are useful for making prediction and why. List top 5 features that contribute to the prediction the most. If not all features are useful, list those unuseful features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Defining preprocessor with extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining features\n",
    "cat_attribs2 = [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\"]\n",
    "num_attribs2 = [\"balance\",\"campaign\",\"day\",\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor2 = get_preprocessor(num_attribs2,cat_attribs2,age_col=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking_prepared2 = preprocessor2.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justification for score function recall:**\n",
    "\n",
    "The current practice of the data team is to build such propensity models and predict customer's probability to adopt the product and target them from the highest probability to the lowest probability. We need to factor in that telemarketing incurs costs for contacting the customer. However, considering the oppurtunity costs of missed memberships are larger than the costs of contacting people who don't acquire the product (i.e., false positives), the cost of of false negatives is highest. In order to minimze the false negative rate, we need to consider recall as score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8896570796460177.\n",
      "Recall is 0.19621749408983452.\n",
      "Precision is 0.5845070422535211.\n",
      "\n",
      "Best alpha: 1.0\n",
      "Average score for alpha 1.0: 0.18921568627450983\n"
     ]
    }
   ],
   "source": [
    "alpha_list = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "log_reg_cv2 = LogisticRegressionCV(penalty=\"l1\", solver='liblinear',random_state=42, max_iter=1000, n_jobs=-1, Cs=alpha_list, scoring=\"recall\")\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg_cv2.fit(banking_prepared2,y)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred2 = log_reg_cv2.predict(banking_prepared2)\n",
    "\n",
    "#Calculate the precision score and avoid the warning message\n",
    "precision = precision_score(y, y_pred2, pos_label=\"yes\",zero_division=1)\n",
    "recall = recall_score(y, y_pred2, pos_label='yes')\n",
    "accuracy = accuracy_score(y, y_pred2)\n",
    "\n",
    "print(f\"Accuracy is {accuracy}.\")\n",
    "print(f\"Recall is {recall}.\")\n",
    "print(f\"Precision is {precision}.\")\n",
    "print(\"\")\n",
    "print('Best alpha:', log_reg_cv2.C_[0])\n",
    "print(f\"Average score for alpha {log_reg_cv2.C_[0]}:\",log_reg_cv2.scores_[\"yes\"].mean(axis=0).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does model performance improve?**\n",
    "\n",
    "The model performance improves when using l1 regularization and setting \"recall\" as score function. Altough the accuracy is about the same (0.88) the recall score improved from 0.0 to 0.20. By combining L1 regularization with \"recall\" as the score function, the model is encouraged to select only the most relevant features while also prioritizing the identification of all positive cases, which leads to improved performance given the cost of false negatives is high in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Feature Importance Ranking\n",
    "\n",
    "In order to determine what features contribute to prediction the most the coefficients of the best model (log_reg_cv2) are considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 features that contribute to prediction the most are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>abs_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duration</td>\n",
       "      <td>1.026792</td>\n",
       "      <td>1.026792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>loan_yes</td>\n",
       "      <td>-0.795112</td>\n",
       "      <td>0.795112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>housing_yes</td>\n",
       "      <td>-0.754531</td>\n",
       "      <td>0.754531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job_retired</td>\n",
       "      <td>0.716577</td>\n",
       "      <td>0.716577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>job_entrepreneur</td>\n",
       "      <td>-0.664743</td>\n",
       "      <td>0.664743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  coefficient  abs_coefficient\n",
       "3           duration     1.026792         1.026792\n",
       "28          loan_yes    -0.795112         0.795112\n",
       "26       housing_yes    -0.754531         0.754531\n",
       "9        job_retired     0.716577         0.716577\n",
       "6   job_entrepreneur    -0.664743         0.664743"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving the names of the input features \n",
    "num_attribs = preprocessor2.named_transformers_['num']['selector'].attribute_names\n",
    "cat_attribs = preprocessor2.named_transformers_['cat']['cat_encoder'].get_feature_names_out(cat_attribs2)\n",
    "age_attribs = ['age_quartile_0', 'age_quartile_1', 'age_quartile_2', 'age_quartile_3']\n",
    "\n",
    "feature_names = np.concatenate([num_attribs, cat_attribs, age_attribs])\n",
    "\n",
    "# retrieving the coefficients of log_reg_cv2\n",
    "coefficients = log_reg_cv2.coef_.flatten()\n",
    "\n",
    "# Create a DataFrame with coefficients and feature names\n",
    "coef_df = pd.DataFrame({'feature': feature_names, 'coefficient': coefficients})\n",
    "\n",
    "coef_df['abs_coefficient'] = coef_df['coefficient'].abs()\n",
    "print(\"The top 5 features that contribute to prediction the most are: \")\n",
    "coef_df.sort_values(by=\"abs_coefficient\",ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 8 features in the table below have coefficients equal to zero, meaning they have no impact on the target variable. They should therefore be left out of the model. In addition, discarding features with a significantly small coefficients (for instance, smaller than 0.10) might benefit the model as it reduces  chances of overfitting (and therefore ensures a low variance error). As a consequence, a list of features to drop constitutes:\n",
    "\n",
    "education_primary,\n",
    "job_services,\n",
    "job_self-employed,\n",
    "age_quartile_2,\n",
    "balance,\n",
    "marital_single,\n",
    "age_quartile_1,\n",
    "day,\n",
    "education_secondary,\n",
    "default_yes,\n",
    "housing_no,\n",
    "job_technician,\n",
    "loan_no,\n",
    "job_housemaid,\n",
    "age_quartile_0,\n",
    "marital_divorced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with sorted coefficients:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>abs_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>education_unknown</td>\n",
       "      <td>-0.252111</td>\n",
       "      <td>0.252111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>job_management</td>\n",
       "      <td>0.184916</td>\n",
       "      <td>0.184916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>job_unemployed</td>\n",
       "      <td>-0.174915</td>\n",
       "      <td>0.174915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>age_quartile_3</td>\n",
       "      <td>0.103570</td>\n",
       "      <td>0.103570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>education_primary</td>\n",
       "      <td>-0.089949</td>\n",
       "      <td>0.089949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>job_services</td>\n",
       "      <td>-0.058401</td>\n",
       "      <td>0.058401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>job_self-employed</td>\n",
       "      <td>-0.053161</td>\n",
       "      <td>0.053161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>age_quartile_2</td>\n",
       "      <td>-0.037910</td>\n",
       "      <td>0.037910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>0.026998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>marital_single</td>\n",
       "      <td>-0.020998</td>\n",
       "      <td>0.020998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>age_quartile_1</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>0.004423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>day</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>education_secondary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>default_yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>housing_no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>job_technician</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>loan_no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>job_housemaid</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>age_quartile_0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>marital_divorced</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  coefficient  abs_coefficient\n",
       "14    education_unknown    -0.252111         0.252111\n",
       "15       job_management     0.184916         0.184916\n",
       "16       job_unemployed    -0.174915         0.174915\n",
       "17       age_quartile_3     0.103570         0.103570\n",
       "18    education_primary    -0.089949         0.089949\n",
       "19         job_services    -0.058401         0.058401\n",
       "20    job_self-employed    -0.053161         0.053161\n",
       "21       age_quartile_2    -0.037910         0.037910\n",
       "22              balance     0.026998         0.026998\n",
       "23       marital_single    -0.020998         0.020998\n",
       "24       age_quartile_1    -0.004423         0.004423\n",
       "25                  day     0.000638         0.000638\n",
       "26  education_secondary     0.000000         0.000000\n",
       "27          default_yes     0.000000         0.000000\n",
       "28           housing_no     0.000000         0.000000\n",
       "29       job_technician     0.000000         0.000000\n",
       "30              loan_no     0.000000         0.000000\n",
       "31        job_housemaid     0.000000         0.000000\n",
       "32       age_quartile_0     0.000000         0.000000\n",
       "33     marital_divorced     0.000000         0.000000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Table with sorted coefficients:\")\n",
    "coef_sorted = coef_df.sort_values(by=\"abs_coefficient\",ascending=False)\n",
    "coef_sorted.reset_index(drop=True,inplace=True)\n",
    "coef_sorted.index += 1\n",
    "coef_sorted.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3 (10 points)\n",
    "\n",
    "Now use the best model found in the cross-validation to predict the test set, show the obtained confusion matrix. Assume that targeting each customer would cost 10 euros and if the customer subscribe, the company would earn 50 euros. If we perform targeted telemarketing to all customers that are predicted to subscribe in the test set, what's the resulting profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[792  15]\n",
      " [ 75  23]]\n",
      "\n",
      "True Negatives: 792\n",
      "False Positives: 15\n",
      "False Negatives: 75\n",
      "True Positives: 23\n"
     ]
    }
   ],
   "source": [
    "#retrieve the actual y values of the test set\n",
    "test_y = test_data[\"y\"]\n",
    "\n",
    "# transform test data with preprocessing pipeline\n",
    "test_data_transformed = preprocessor2.transform(test_data)\n",
    "\n",
    "# use best model (log_reg_cv2) to make predictions\n",
    "test_pred = log_reg_cv2.predict(test_data_transformed)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = metrics.confusion_matrix(test_y, test_pred)\n",
    "\n",
    "tn = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "\n",
    "print(cm)\n",
    "print(\"\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting profit would be equal to 770\n"
     ]
    }
   ],
   "source": [
    "subscription = 50 \n",
    "target_cost = 10 \n",
    "\n",
    "class Profit():\n",
    "    def __init__(self):\n",
    "        self.subscription = 50\n",
    "        self.target_cost = 10\n",
    "    \n",
    "    def profit_calc(self, tp, fp):\n",
    "        profit_tp = tp*(self.subscription-self.target_cost)\n",
    "        loss_fp = fp*(-self.target_cost)\n",
    "        profit = profit_tp + loss_fp \n",
    "        return profit\n",
    "    \n",
    "profit = Profit().profit_calc(tp,fp)\n",
    "print(f\"The resulting profit would be equal to {profit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.4 (10 points)\n",
    "\n",
    "Now adjust the decision threshold in order to optimize the obtained profit. What would be the resulting threshold and profit? Is the propensity model built based on the targeting predicted probability useful in terms of profit maximizing? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_y = train_data[\"y\"]\n",
    "train_y_en = le.fit_transform(train_y)\n",
    "test_y = le.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first we explore relatinoship between recall and precision\n",
    "y_scores = cross_val_predict(log_reg_cv2, test_data_transformed, test_y, cv=5, method=\"decision_function\")\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(test_y, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.xlim([-10, 10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update Profit class with optimization method \n",
    "class Profit():\n",
    "    def __init__(self):\n",
    "        self.subscription = 50\n",
    "        self.target_cost = 10\n",
    "        self.le = LabelEncoder()\n",
    "    \n",
    "    def profit_calc(self, tp, fp):\n",
    "        self.profit_tp = tp*(self.subscription-self.target_cost)\n",
    "        self.loss_fp = fp*(-self.target_cost)\n",
    "        self.profit = self.profit_tp + self.loss_fp \n",
    "        return self.profit\n",
    "    \n",
    "    def profit_maximization(self,model):\n",
    "            \n",
    "        profits = []\n",
    "        thresholds = np.linspace(0,1,num=1000)\n",
    "            \n",
    "        for threshold in thresholds:\n",
    "                \n",
    "            # Use predict_proba to compute the probabilities for each customer\n",
    "            probabilities = model.predict_proba(test_data_transformed)[:, 1]\n",
    "            \n",
    "            # Compute the predicted labels based on the threshold\n",
    "            y_pred = (probabilities >= threshold).astype(int)\n",
    "            \n",
    "            # confusion matrix\n",
    "            confusion_matrix = metrics.confusion_matrix(test_y, y_pred)\n",
    "            \n",
    "            # Calculate number of true positives and false negatives\n",
    "            tp = confusion_matrix[1, 1]\n",
    "            fp = confusion_matrix[0, 1]\n",
    "            \n",
    "            # Calculate profit\n",
    "            profit = self.profit_calc(tp, fp)\n",
    "            \n",
    "            # Store the profit\n",
    "            profits.append(profit)\n",
    "            \n",
    "        # Plot the profits as a function of the threshold\n",
    "        plt.plot(thresholds, profits)\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Profit')\n",
    "        plt.title('Profit as a function of the threshold')\n",
    "        plt.show()\n",
    "            \n",
    "        # Print the threshold value that maximizes the profit\n",
    "        optimal_threshold = thresholds[np.argmax(profits)]\n",
    "        print(\"Optimal threshold: {:.2f}\".format(optimal_threshold))\n",
    "            \n",
    "        # Print the profit at the optimal threshold\n",
    "        optimal_profit = profits[np.argmax(profits)]\n",
    "        print(\"Optimal profit: {:.2f} euros\".format(optimal_profit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize class \n",
    "best_threshold = Profit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvyklEQVR4nO3deXxcZb3H8c8vSZO0abonbelOV1qkhZYCylYKtKACCmIVZVUEQa6Iish1FxXvvSKgoCjKIrKoIAgiq2zSUlqgLRS6b6FbtjZLm/13/zgnYZpmmbazJDPf9+s1r5x5zjLPMzM5v3mW8xxzd0RERA5URrIzICIiqUEBRUREYkIBRUREYkIBRUREYkIBRUREYkIBRUREYkIBRfabmX3EzFaZWZWZnWVmT5rZBcnOV0fMrKeZ/cPMdprZXxL82u+Y2YkJfk0zsz+aWbmZLYxyn7vM7MdxzJOb2bh4HT/iddab2cn7uW+7eTSzC83slQPLXWpSQEkz4T/Z7jAIbAtPNr3383A/BH7l7r3d/e/ufpq73x2+Tlf9pzsHGAwMdPdPxetF2jopu/sUd38hXq/ZjmOBU4Dh7j6z9cp4f05m9oKZfSFex5euRQElPX3c3XsDRwBHAv/degMzy4riOKOAd2Kct3gbBax094ZkZyRBRgHr3b062RnZH1F+D6WrcHc90ugBrAdOjnj+P8Dj4bIDVwCrgHVh2heB1UAZ8BhwUJi+BmgCdgNVQA7wAvAF4BCgBmgM1+1oJy8XAe8ClcBa4EsR6wYBjwM7wtd+Gcho5zg3A5uACmAxcFw72/0AqAPqw3xdAnwf+FPENqPD9yErfP4C8CPgP2E+nwYGRWx/LPBqmM9NwIXApeFr1IWv84/W7334fv0S2Bw+fgnkhOtOBIqAa4DtwBbgog4+04PCz6Ys/Ky+GKZf0upz+EGr/dr8nIC7gF8DT4Rlfg0YG7HfJOCZ8PVWAOe2k68bwmPXhMf/VcT37DKC71l5+FoWrrswfK9vCo//4/C9+l9gI7AN+A3Qs7PvSfh+fx1YCuwEHgRyI/LX5nc7Io/jwuWB4foKYGH4fXgl2f/LXfGR9AzokeAPfM+T2giCGsaPwucenigGAD2Bk4ASgppMDnAr8FJbxwqfvwB8IVy+sLN/OuCjwFjAgBOAXcAR4bqfhieOHuHjuOaTThvH+Vz4T59FcBLeGnniaLXt99kzgLR+Ppq9A8oaYEL4nrwA/CxcN5LghPuZMI8DgWnhuruAH3fw3v8QWAAUAgUEQan5czgRaAi36QGcHr43/dsp04vAbUAuMA0oBmZH8zm0tT7MexkwM3xP7wMeCNflEQTOi8J1R4TfkSntHL/lOxGR5gRBoF/4HhYDcyPy0wB8JTx+T4Jg+xjB9zIf+Afw086+J+H7vZAg4A4g+PFyWbius+92ZEB5AHgoLPuhwPsdvafp/FCTV3r6u5ntAF4hOBn9JGLdT929zN13A+cBf3D3N9y9FrgOOMbMRsciE+7+hLuv8cCLBL/+jwtX1wNDgVHuXu/uL3v4393Gcf7k7qXu3uDu/0dwgpgYizyG/ujuK8P35CGCkzYE78+z7n5/mMdSd38rymOeB/zQ3be7ezFB7enzEevrw/X17v5Pgl/4e5XJzEYQ1JKudfea8PV/3+pY++Nhd1/oQdPgfXxQ5o8RNKH9MXy/3wD+RtA3tS9+5u473H0j8O+I4wNsdvdbw9euIahJXB1+LysJvq/zwm07+57c4u6b3b2MIBA1v05U320zywTOBr7r7tXu/jZw9z6WNW0ooKSns9y9n7uPcvcvhyfKZpsilg8CNjQ/cfcqoBQYFotMmNlpZrbAzMrCAHc6QRMGBE1xq4GnzWytmX2rg+NcY2bvhiO3dgB9I44TC1sjlncBzYMYRhDUXvbHHu9tuHxQxPNS37OfJ/J1Wx+n+UQbeawD/YzaK/Mo4Cgz29H8IDg5D4nR8WHP72AB0AtYHPF6/wrTofPvSXuvE+13u4CgphSZpw1ImxRQpLXIX3ebCU4gAJhZHkGzzvv7eJy9mFkOwS/b/wUGu3s/4J8EzV+4e6W7X+PuBwMfB75mZrPbOM5xwLXAuQRNQv0I2sstijwCVBOcsJrty4lxE0GTXVs6m8Z7j/eWoOln8z68duRxBphZfqtjRfMZQef5bG0T8GL4g6T50dvdL4/R8VvvU0LQTzcl4vX6ejCoJOrvSRui/W4XEzTBjYhIG7nPJUoTCijSkT8DF5nZtDAA/AR4zd3XR7HvNmC4mWW3sz6boGmqGGgws9OAU5tXmtnHzGycmRlBZ2hj+Ggtn+AfvhjIMrPvAn2iKl3gLeB4MxtpZn0Jmj6idR9wspmda2ZZZjbQzKaF67YBB3ew7/3Af5tZgZkNAr4L/GkfXhsAd99E0P/yUzPLNbPDCDrj74vyEJ19Tq09Dkwws8+bWY/wcaSZHdLB8Tt6Hzrk7k3A74CbzKwQwMyGmdmccDna70lrUX233b0ReBj4vpn1MrPJQJe+1iqZFFCkXe7+HPAdgprEFoJf4/M63OkDzxN0+G81s5I2jl0JXEXQJ1EOfJag47XZeOBZgr6D+cBt3vY1HE8BTwIrCZoiatizeaJD7v4MweifpQQjxB7fh303EjTTXUPQif0WMDVcfScwOWym+Xsbu/8YWBS+7jLgjTBtf3yGYDDBZuAR4HthuaLR4efUWvi5nUrwPdhM0KR0I8GPg7bcDJwTXlh5S5R5au1agmatBWZWQfC9aO5PivZ70roc+/LdvpKgqWwrwYCFP+5nOVJe82gIERGRA6IaioiIxIQCioiIxIQCioiIxIQCioiIxETaTrw2aNAgHz16dLKzISLSrSxevLjE3QvaWpe2AWX06NEsWrQo2dkQEelWzKzdmQLU5CUiIjGhgCIiIjGhgCIiIjGhgCIiIjGhgCIiIjGhgCIiIjGhgCIiIjGhgJKG3n5/J4vWlyU7GyKSYtL2wsZ09rFbXwFg/c8+GvNjNzY57k5WZvBbpbahkayMDDIzor2Booh0VwooaWT55gpOv+XllufuTnCju9hYta2SS+9dTJM7XzlpPP9ctoWXVxXTt2c23/nYIby0soRh/XL52qkTOz+YiHQ7aXuDrRkzZng6Tb2yalslp9z00l7p+blZvH79yeT2yDyg4+/cXc+cm15ia0VNS1p2VgZ1DU17bXvt3ElcfmJ7t2IXka7MzBa7+4y21qkPJQXd/sIazvzVK6wrqW5Ju2d+MP3OzDEDuOCYUS3plTUN/O2NojaP4+5sq6ihrR8dDY1N7K4Lbt29eEMZx974PFsravjaKROYNCSf608/hCXfPZW3fzCHr548nj9edCS//PQ0AG7813stx6mqbaCpKT1/1IikGjV5dRPbKmr40ePLueTYMfTrlc2YQXltbrdzdz0/f+o93OF/n17BzZ+extqSau5dsIHZkwq588IjaWxy8nN78Oamcv6zupR3t1RQVdvAf1aXMHtSIVmZGWzesZsbnniXJ5Zt4QdnTCE/N4vqMIAUle/ity+uZXj/npx9xHBuf3ENfXJ7cMuFhzNrUiFXzR6/R56+evKEluVH3nyf+WtLuXf+euobnR8+vpz/mj2eq0+ZgIh0b2ry6ia+9belPPD6ppbnbXWo/2nBBu58ZR3rSqoZNbAXG0p37bH+p5/8EJ+ZOXKPtPN+v4D/rC5teX77eUcw99AhnP+Hhby8qiSqvI0v7M0d589oN8hFemVVCZ+787W90hf998kM6p0T1euJSPJ01OSlgNJNfOaOBcxf+8GJv3VAufxPi3ny7a0AnHzIYK6YNZZP3PYqAMP69eSij4zm4o+MIaPVaKtV2yp57r3t/OzJD5qhhvTJZWtFDVfOGsera0p4Y+MOABZ+e3ZLJ375rjque3gZnz96FGdOO2ifOvd37qqnrjHoW3lm+Ta+/cgyAFb8eC45WQfWlyMi8dVl+1DM7A9mtt3M3o5IG2Bmz5jZqvBv/4h115nZajNbYWZzItKnm9mycN0tFsuhS11AXUMTizeU75EW+UNg0fqylmACcOnxB3P4yP6suuE0vvOxyfzrq8fxheMO3iuYAIwfnM9lJ4xl2fdP5aqTxgGwtaKGUycP5ppTJ3DXxTOZOrwvf7v8GAr75FKQn0NBfg4TBufzt8s/zFmHD9vnkWJ9e/VoOc7Z04e1pL/9/s59Oo6IdC3J7pS/C5jbKu1bwHPuPh54LnyOmU0G5gFTwn1uM7Pmn7O3A5cC48NH62N2a+9traCusYlff/YIfnHuVAD+sXQLAGXVdXz+zoUAPPlfx/HcNScwc8wAAHpkZnDJsWPIz+3R6Wvk5/bg6lMmcM0pE/i/T03lV589AjOjT24PHr3yWKaPGhCXsuVkZbLw+tkAewTN+sa9R4eJSNeW1E55d3/JzEa3Sj4TODFcvht4Abg2TH/A3WuBdWa2GphpZuuBPu4+H8DM7gHOAp6Mc/YTZklR8Mv9sOF9GdavJ//39EoeX7KZxqYmrn5wCRD0fRwytM8BvY6Z8ZVWHeqJUJify8gBvVi0vpxJQ4q5d8EGXlixnctOGMs1B3jNyqayXdz0zEp21TWSnZXBdadPItOMNzftAODgQXmMH5wfg1KISFcc5TXY3bcAuPsWMysM04cBCyK2KwrT6sPl1ul7MbNLCWoyjBw5sq1NuqQlm3YwMC+b4f17YmYcPrIfzyzfxtPLt7Vsc9qHhiYxhwduxqj+PPzm+zy9fBtZGUZDk/P8e9s5bHg/Vm2v5PITxrbbtObuvLe1kl3hKLR1JdW8tamcLTtqeO697fTKzmR4/56s3FbFY0s2YwbNLYYD8rK5+6KZ/Pyp93h3SyV/ueyYqAYXiMjeumJAaU9bZxPvIH3vRPc7gDsg6JSPXdbia2nRDqaO6NdyQj1kaB8eD5u8cntkcPO8w5OZvZj48qyxDMrPIS87i88fM4rfvbyW219YwxfvCQZObN1Zw4UfHk1eThZ1DU2sL63mqXe2smBtGaVVtZTvqt/rmAPzsjlpUiFfO2UChw7ry7E3Pk9R+W6OHD2AL584liWbdnLTsyv5+K9eadnn639Zwl++dEyb/U0i0rGuGFC2mdnQsHYyFNgephcBIyK2Gw5sDtOHt5GeEqpqG1i1vYrTI2ogHxrWF4APjx3In794dLKyFlPjCvP59umHtDyfNqLfHuvvmb+h5eLMSOMLe3P8hAJG9O/FjNH9MTMyDGaMGkDP7D1HjN3/xaNpcmfUwKAGctjwfmzesZth/Xty2qFDOPe381m8oZwn395KZU09PbMz+fhhBym4iESpKwaUx4ALgJ+Ffx+NSP+zmf0COIig832huzeaWaWZHQ28BpwP3Jr4bMfHsqKduMPUiBPsseMG8ZvPHRG3jvKu4ORDBnPPxTP58NiBvLiymEvuDmoqn54xgiPHDCDD4IQJBQzIy456lNmIAb32eD4gL5sbzzms5flTVx/PzBue44o/v9GSVtA7hw+PGxSDEomkvqQGFDO7n6ADfpCZFQHfIwgkD5nZJcBG4FMA7v6OmT0ELAcagCvcvTE81OUEI8Z6EnTGp0yH/NKiHQBMHd6vJS0jw5h7aPfuM+lMZoZx/IQCAGYfMph/f/1Eisp3cdz4gri9ZmF+Lrd+5nCKynczcUhvLr5rERfe9TrZmRnk9sjkoS8dzcEFveP2+iLdnS5s7MIam5zx1/+Tg/r15JVrT0p2dtLOn1/byJriKuoamrh3wQYmDO7NPRcfxZC+ucnOmkjSdHRhY1ds8pLQ1ooamlo1d0nifPaoYCSgu7N4QznLt1TwuTtf49ErPkJeTuz+deoammhyJzPD6JGZ7EvDRPafAkoX9uX7grb8c2eM6GRLiScz44mrjuXSexfzzPJtPPj6Ji4+dgw19Y3MX1tKQ2P7tfxpI/pRkP/BHGUNjU3MX1tKTX1w4eYrq4q5Z8EG3IPp/p/4yrG6Lka6LTV5dVGlVbVM//GzALz8zVl7dShL4jU0NjHth89Q29BIblYmlbUNne4zZ8pgvvOxydz1n/WsLanm3yu20/pfLjsrg8tOGMstz60CgsECt593BEcdPDAexRA5IGry6oaag8kPzpiiYNJFZGVm8MtPT+PVNR9M0nnI0Px2Zyi4+blV/Pu9YuaveZnd9Y30zsli1sRCZk0q5PCIZszh/XvSt2cP3txYTm6PTF5YsZ1r/rKEZ64+Ya+hzyJdmQJKF1RSVduyfPb04R1sKYl28uTBnDx5cFTbfuWkcfTKzsSAiz4yptO+sHsvOQqAc387n4Xrynhi2RY+PnUo2ZkZMb1Vs0i8qMmrC1q4roxzfzufb8yZyBWzxiU7O5JgDY1NHPr9p1r6Wc6dMZyfnzM1ybkSCajJq5t5f0dwY6y5hw5Jck4kGbIyM7j9c9NZvrmCZ9/dxpNvb6VXdvCvetz4Qcw+JLoakkiiKaB0QetKdmEGB/XtmeysSJLMmljIrImFjC/szbceXsYjb77P7rpG/r1iuwKKdFkKKF3Q6+vKOGRIH3XICqdOGcKpU4Ka6u0vrOHGf73Hjl119OuVvcd2TU3Ov1ds36P/LVJBfg4nTVIgkvhSQOliauobeWNjOZ87elSysyJdzNQRwaSgV/75Tfr2+uCmaU1Nzksri6mua2xvVwBe+sYsRg7UiEGJHwWULmbJph3UNjRxtK5BkFYOH9GfmWMGsGXnbrbs3L3HuvGD8zlj6kGcOmUwGa1GhK0pruLzdy7ktJtfYvroAdxz8cxEZlvSiAJKF7MsvK/6ESP7JTcj0uX0zM7koS8ds8/7DemTyzfmTOSVVSW8tLKYXz67cq8pXorKd/H6+nKOGz+I7318SqyyLGlGAaWL2Vi2iz65WQzIy+58Y5EoZGQYV8wax4kTC/jEr1/ll8+uanfbjWW7mDQkn9ED83SlvuwzBZQuZtn7Oxlb2FsXsknMTTmoL8t/OIemdi49e2V1MRfftYhr/7aMHpnG0u/NwQxeW1dGY1NwTUyPzAyOPnigJrGUNimgdCHbK2p4a9MOrj55QrKzIikqq4NAcNKkwSy8fjYvrijmG39dysyfPEtlzd7zlf387MM498hgwtKGxibe21pJ75wsRg/Ki1u+pXtQQOlCnnl3G+4wZ4ouaJTkKMzP5eNTD2JdSTXV4eSXU4b1ZWI4A/IFf1zIT598lzteXgvA1p01VIXbPX/NCboBWZpTQOlCXltbxkF9c5kwWP+Ukjy5PTL55txJba775pxJ/Gd1ScvziYPzGTGgF795cQ1fvu8N+vfquO8vIwOunDWeY8aqfyYVKaB0Ecs3V/DYks2cMKFA/SfSZX32qJEtNx5r1tTkbK+soahsN43tddCE3tq0k9teWE1NQ/vXzGRnZnDUmAEdNs9J16SA0kWc+etXgGCIp0h3kpFh/OLcaVFte+Wf3+DxpVt4eVVJh9t98bgxnDltWFTHHNwnd4+bmEnyKKB0EfXhXf8yM1U7kdR149mHccmxYzrc5hO3vcrvXl7H715eF9UxC/JzWPjt2arZdwEKKF3A/Qs3tiyffYTufyKpKy8ni8NH9u9wmxs+cSg7d9czvrDzWyG/traU37+yjk//dgEjBvTi5+ccRmaGAkuyKKB0AU8s3QLAbecdwfRRHf+ziaS6846Kfh67qSP6smJbJe+X72bh+jKuPmU8w/trvrJkUUBJMnensraBMYPyOE33PxHZJ4X5udx7yVH8e8V2Lvrj62yrqNkroKwprmJ3BxNn9s/LZlg/3SoiFhRQkmxNcRVLNu3gG3Mmqg1YZD81D2a56v63yMv54LYPO3bVs72y7Sn9m/XINBZcN5tGd3plZ9E7R6fF/aV3Lsne2LgDQLUTkQMwvrA35x01krLqur3WjRqY1+5kq+tLq/nJP9/j5F+8SPmuenKyMnj52lkU5mu05f5QQEmyovLdmKF2X5EDkJWZwQ2f+NA+71fb0MjiDeWUVdcxrF9P/v7WZq5+8C0Kekc3DDknK5Ovz5moYcshBZQke798N4Pzc8nO0kVcIomWk5XJbz8/A4C6hia27KyhqHw3ReW7O9kTmtzZVLabwj45zG2jhWHMoDx6ZafXKTa9StsFLd9SwXhNtSKSdNlZGTy4D/ebcXeO/ulz3Pr8am59fvVe60+ZPJjfnT+DnbvqqW3cc1DA0k072bJzN/NmjkypmZtTJqCY2VzgZiAT+L27/yzJWepUbUMjK7dVctKkg5OdFRHZR2bGfV84mjXFVXutu3/hRl5eVcxHb3mZdzZXtHuMIX17csrkwQAs3lDG+pJde23T5M78NaVMGprPpcePjV0B4iAlAoqZZQK/Bk4BioDXzewxd1+e3Jx1bF1JNY1NzoTBnV/AJSJdz7jC3owr3LuFoX+vbHbVNtLoztlHDOfwNgYF/Pff3+aL9yyK+rWylhiThvQBIDPDmD6qP7k9MjvZa29VtQ1xG8mWEgEFmAmsdve1AGb2AHAm0KUDysptwS8bBRSR1DJzzAAeuqzj5rP+vbJZua2y5Xl+bhYnTCggJ2vvIPHMu9v40ePLOf8PC1vSvjFnIlfMGoe7s66kmtqGpj32WbShnI2l1Xuk1Tc6j7z5Pt/92GTOnh77WTlSJaAMAzZFPC8Cjmq9kZldClwKMHLkyNarE+6NDeVkWNB5JyLp5aOHDeWjDI1q2ws/PJojR/envjEIGt/4y1J+++Ia/rFkM+W76thW0f61Nr2y9wxQhfk5TGtnGPWBSpWA0tYVgXvNo+3udwB3AMyYMaPjebbjrKKmngdf38Spk4fsV7VVRNJHZoZx2PB+Lc+/esoEHl+yGYCRA3oxpiCPw0f022OfntlZfGTswITeBiBVAkoRMCLi+XBgc5LyEpVV2yrZXd/Ip48c0fnGIiIRzph6EGdMPSjZ2dhLqoxXex0Yb2ZjzCwbmAc8luQ8dag4nA6isI8uiBKR1JASNRR3bzCzK4GnCIYN/8Hd30lytjrUHFB0ha2IpIqUCCgA7v5P4J/Jzke01hRXk5OVwYBO7sEtItJdpEqTV7fzxsZyZozur/tmi0jK0NksSbZV1OgeDCKSUhRQkqCpySmpqlP/iYikFAWUJCjfVUdjk0c9RbaISHeggJIEJVXBTYAKdBMfEUkhCihJ0DxkeFBvjfASkdShgJIEWytqAF2DIiKpRQElCV5cWczAvGzd9ldEUooCShKs3FrJ4SP767a/IpJSdEZLsLqGJlZsq2TUQNVORCS1KKAk2Dm/eRWAsQW6j7yIpBYFlARbWrQTgGPHDUpyTkREYitlJofsLiYP7cPgPjmMVJOXiKQY1VASbHtlLUP66oJGEUk9CigJ1NDYRGl1ra6QF5GUpICSQCVVdbhDoS5oFJEUpICSQNsrgyvkFVBEJBUpoCTQB/eRV5OXiKQeBZQEKqnSfeRFJHUpoCSQZhkWkVSmgJJAxZW19MnNIicrM9lZERGJOQWUBCquqlVzl4ikLAWUBCquVEARkdSlgJJAQUDRCC8RSU0KKAlUXFlLQW/VUEQkNSmgJEh1bQPVdY0MytcILxFJTQooCbKt+T7yqqGISIpKSkAxs0+Z2Ttm1mRmM1qtu87MVpvZCjObE5E+3cyWhetuMTML03PM7MEw/TUzG53g4kRl5bZKAMYPzk9yTkRE4iNZNZS3gU8CL0UmmtlkYB4wBZgL3GZmzRdt3A5cCowPH3PD9EuAcncfB9wE3Bj33O+H5ZsryDCYqIAiIikqKQHF3d919xVtrDoTeMDda919HbAamGlmQ4E+7j7f3R24BzgrYp+7w+W/ArObay9dyfItlYwZlEfPbF3UKCKpqav1oQwDNkU8LwrThoXLrdP32MfdG4CdwMC2Dm5ml5rZIjNbVFxcHOOsd2x9aTXjCnUfeRFJXXELKGb2rJm93cbjzI52ayPNO0jvaJ+9E93vcPcZ7j6joKCg4wLEkLtTVL6LEf11218RSV1xu6e8u5+8H7sVASMing8HNofpw9tIj9ynyMyygL5A2X68dtwUV9VSU9/EiAEKKCKSurpak9djwLxw5NYYgs73he6+Bag0s6PD/pHzgUcj9rkgXD4HeD7sZ+kyNpXtBmDEgJ5JzomISPzErYbSETP7BHArUAA8YWZvufscd3/HzB4ClgMNwBXu3hjudjlwF9ATeDJ8ANwJ3GtmqwlqJvMSV5LobCrbBaAmLxFJaUkJKO7+CPBIO+tuAG5oI30RcGgb6TXAp2Kdx1hatb2SzAxj5EAFFBFJXVE1eZnZc9GkSdvWlVQzckAv3QdFRFJahzUUM8sFegGDzKw/H4yo6gMcFOe8pYzSqjpNuSIiKa+zJq8vAV8lCB5vRKRXAL+OU55STll1HWMLdA2KiKS2DgOKu98M3GxmX3H3WxOUp5RTvquO/nmaZVhEUltnTV4nufvzwPtm9snW69394bjlLEU0NTnlu+oZqIAiIimusyav44HngY+3sc4BBZROVNTU09jkqqGISMrrLKCUh3/vdPdX4p2ZVFRWXQfAgLweSc6JiEh8dTZs+KLw7y3xzkiq+iCgaJSXiKS2zmoo75rZeqDAzJZGpBvg7n5Y3HKWIrbsDO7UWJivgCIiqa2zUV6fMbMhwFPAGYnJUmrZGE67MkpXyYtIiut06hV33wpMNbNsYEKYvMLd6+OasxSxvqSagvwcemUnZZYbEZGEieosZ2YnENwlcT1Bc9cIM7vA3V/qcEdhQ+kuxgzMS3Y2RETiLtqfzb8ATm2+ba+ZTQDuB6bHK2OpYkNZNceNT9zNvEREkiXa+6H0iLwHvLuvBDQOthO76hrYVlHLaPWfiEgaiLaGstjM7gTuDZ+fByyOT5ZSR/ONtUaqyUtE0kC0AeUy4ArgKoI+lJeA2+KVqVRRUlULwGANGRaRNNBpQDGzDGCxux9K0JciUWoOKAM1db2IpIFO+1DcvQlYYmYjE5CflFJaFVwlP6i35vESkdQXbZPXUOAdM1sIVDcnursuduxAaXUtWRlGn1yNXxCR1BdtQPlBXHORokqr6hiQl01GhnW+sYhINxfNLYAvA8YBywhmHW5IRMZSQUlVnfpPRCRtdNaHcjcwgyCYnAb8X9xzlEJKq2vVfyIiaaOzJq/J7v4hgPA6lIXxz1LqKK2qY9QAXdQoIumhsxpKywSQaurad6VVtWryEpG00VkNZaqZVYTLBvQMnzffD6VPXHPXje2ua6S6rpGBavISkTTR2f1QMhOVkVRTWh1c1DhId2oUkTQR7eSQso+aL2pUDUVE0kVSAoqZ/Y+ZvWdmS83sETPrF7HuOjNbbWYrzGxORPp0M1sWrrvFzCxMzzGzB8P018xsdOJLtLfmGor6UEQkXSSrhvIMcGh4T/qVwHUAZjYZmAdMAeYCt5lZc7Pb7cClwPjwMTdMvwQod/dxwE3AjYkqREdKmmsoeaqhiEh6SEpAcfenI0aNLQCGh8tnAg+4e627rwNWAzPNbCjQx93nu7sT3D3yrIh97g6X/wrMbq69JNOWHTUAFGimYRFJE12hD+Vi4MlweRiwKWJdUZg2LFxunb7HPmGQ2gkMjGN+o7J5x24K8nPI7aFxDSKSHqKdy2ufmdmzwJA2Vl3v7o+G21wPNAD3Ne/WxvbeQXpH+7SVp0sJms0YOTK+kydvrahhaN/cuL6GiEhXEreA4u4nd7TezC4APgbMDpuxIKh5jIjYbDiwOUwf3kZ65D5FZpYF9AXK2snTHcAdADNmzGgz6MRKRU09fXtqlmERSR/JGuU1F7gWOMPdd0WsegyYF47cGkPQ+b7Q3bcAlWZ2dNg/cj7waMQ+F4TL5wDPRwSopKnYXa9p60UkrcSthtKJXwE5wDNh//kCd7/M3d8xs4eA5QRNYVe4e2O4z+XAXUBPgj6X5n6XO4F7zWw1Qc1kXsJK0YHKmgbyc5P19oqIJF5SznjhEN/21t0A3NBG+iLg0DbSa4BPxTSDMVBRU6+AIiJppSuM8ko5tQ2N1NQ3qclLRNKKAkoctNxLXtegiEgaUUCJg+LKYNqVAk27IiJpRAElDloCimooIpJGFFDioLhKAUVE0o8CShyUVDbPNKyJIUUkfSigxEFxVS19e/YgJ0vzeIlI+lBAiYPiylo1d4lI2lFAiYPiylqN8BKRtKOAEgfFVaqhiEj6UUCJgxI1eYlIGlJAibHq2gaq6xoZpCYvEUkzCigxVqJrUEQkTSmgxJiukheRdKWAEmMtNRQ1eYlImlFAiTHVUEQkXSmgxFhxZS0ZBgPyNO2KiKQXBZQYK66qZUBeDpkZluysiIgklAJKjBVX1qm5S0TSkgJKjOkqeRFJVwooMVZSWcsg9Z+ISBpSQImx0upa3QdFRNKSAkoM7aproKa+iYG6BkVE0pACSgyVVtUBGjIsIulJASWGSquDgDJQAUVE0pACSgyVVTffS15NXiKSfhRQYqikSjUUEUlfCigx1NyHolFeIpKOkhJQzOxHZrbUzN4ys6fN7KCIddeZ2WozW2FmcyLSp5vZsnDdLWZmYXqOmT0Ypr9mZqOTUCQgmGk4LzuTXtlZycqCiEjSJKuG8j/ufpi7TwMeB74LYGaTgXnAFGAucJuZZYb73A5cCowPH3PD9EuAcncfB9wE3JioQrRWrFv/ikgaS0pAcfeKiKd5gIfLZwIPuHutu68DVgMzzWwo0Mfd57u7A/cAZ0Xsc3e4/FdgdnPtJdGKK2t1618RSVtJ60MxsxvMbBNwHmENBRgGbIrYrChMGxYut07fYx93bwB2AgPbec1LzWyRmS0qLi6OVVFaaB4vEUlncQsoZvasmb3dxuNMAHe/3t1HAPcBVzbv1sahvIP0jvbZO9H9Dnef4e4zCgoK9q1AUShRQBGRNBa33mN3PznKTf8MPAF8j6DmMSJi3XBgc5g+vI10IvYpMrMsoC9Qtv853z91DU3s2FWvW/+KSNpK1iiv8RFPzwDeC5cfA+aFI7fGEHS+L3T3LUClmR0d9o+cDzwasc8F4fI5wPNhP0tCleqiRhFJc8ka3/ozM5sINAEbgMsA3P0dM3sIWA40AFe4e2O4z+XAXUBP4MnwAXAncK+ZrSaomcxLVCEilVQG16AM0jUoIpKmkhJQ3P3sDtbdANzQRvoi4NA20muAT8U0g/uhpCqooQxSH4qIpCldKR8jLQElTwFFRNKTAkqMNM/jNShfTV4ikp4UUGKktKqWnj007YqIpC8FlBgpqapV7URE0poCSoyUVNUxUP0nIpLGFFBipKRK83iJSHpTQImRkqo6XYMiImlNASUGmpqcsmrVUEQkvSmgxED5rjqaXHdqFJH0poASAy3XoKiGIiJpTAElBkqrmieGVA1FRNKXAkoMVNTUA9C3Z48k50REJHkUUGKgqjaYELl3jq6SF5H0pYASA1VhDUUBRUTSmQJKDFTXBTWUPAUUEUljCigxUFXbQFaGkZOlt1NE0pfOgDFQWVNP79wsgrsTi4ikJwWUGCivrmdALw0ZFpH0poASA6XVtboGRUTSngJKDJRW1TEgTwFFRNKbAsoBampytuysYXCf3GRnRUQkqRRQDlBR+W6qahs4ZGifZGdFRCSpFFAO0PItFQBMVkARkTSngHKA3t1SQYbBhMH5yc6KiEhSKaAcoDXFVYwY0Iue2ZnJzoqISFIpoByg1durGFvQO9nZEBFJOgWUA9DY5KwrqWZsQV6ysyIiknRJDShm9nUzczMbFJF2nZmtNrMVZjYnIn26mS0L191i4TwnZpZjZg+G6a+Z2ehE5X/zjt3UNjSphiIiQhIDipmNAE4BNkakTQbmAVOAucBtZtbcOXE7cCkwPnzMDdMvAcrdfRxwE3BjQgoArC6uAmBsoQKKiEgyayg3Ad8EPCLtTOABd69193XAamCmmQ0F+rj7fHd34B7grIh97g6X/wrMtgTN0vjO+zsBGK+AIiKSnIBiZmcA77v7klarhgGbIp4XhWnDwuXW6Xvs4+4NwE5gYDuve6mZLTKzRcXFxQdcjtfWlXHI0D7008SQIiLE7Y5QZvYsMKSNVdcD3wZObWu3NtK8g/SO9tk70f0O4A6AGTNmtLnNvlhXUs30Uf0P9DAiIikhbgHF3U9uK93MPgSMAZaELVPDgTfMbCZBzWNExObDgc1h+vA20onYp8jMsoC+QFnsStK2mvpGNu/YzSePGN75xiIiaSDhTV7uvszdC919tLuPJggIR7j7VuAxYF44cmsMQef7QnffAlSa2dFh/8j5wKPhIR8DLgiXzwGeD/tZ4upPCzbQ5JpyRUSkWZe6Cbq7v2NmDwHLgQbgCndvDFdfDtwF9ASeDB8AdwL3mtlqgprJvHjnc8mmHfz4iXcpzM/h6IMHxPvlRES6BUvAj/kuacaMGb5o0aJ93u+h1zfxzb8tJSvDeOKq45g4RHN4iUj6MLPF7j6jrXVdqobSHfTr1YNPHj6Mr8wez5hBukJeRKSZAso+OnXKEE6d0tbgNRGR9Ka5vEREJCYUUEREJCYUUEREJCYUUEREJCYUUEREJCYUUEREJCYUUEREJCYUUEREJCbSduoVMysGNuzn7oOAkhhmpztQmdODypweDqTMo9y9oK0VaRtQDoSZLWpvLptUpTKnB5U5PcSrzGryEhGRmFBAERGRmFBA2T93JDsDSaAypweVOT3EpczqQxERkZhQDUVERGJCAUVERGJCAaUDZjbXzFaY2Woz+1Yb683MbgnXLzWzI5KRz1iKosznhWVdamavmtnUZOQzljorc8R2R5pZo5mdk8j8xUM0ZTazE83sLTN7x8xeTHQeYymK73VfM/uHmS0Jy3tRMvIZS2b2BzPbbmZvt7M+9ucvd9ejjQeQCawBDgaygSXA5FbbnA48CRhwNPBasvOdgDJ/GOgfLp+WDmWO2O554J/AOcnOdwI+537AcmBk+Lww2fmOc3m/DdwYLhcAZUB2svN+gOU+HjgCeLud9TE/f6mG0r6ZwGp3X+vudcADwJmttjkTuMcDC4B+ZjY00RmNoU7L7O6vunt5+HQBMDzBeYy1aD5ngK8AfwO2JzJzcRJNmT8LPOzuGwHcvTuXO5ryOpBvZgb0JggoDYnNZmy5+0sE5WhPzM9fCijtGwZsinheFKbt6zbdyb6W5xKCXzjdWadlNrNhwCeA3yQwX/EUzec8AehvZi+Y2WIzOz9huYu9aMr7K+AQYDOwDPgvd29KTPaSJubnr6wDyk5qszbSWo+xjmab7iTq8pjZLIKAcmxccxR/0ZT5l8C17t4Y/IDt9qIpcxYwHZgN9ATmm9kCd18Z78zFQTTlnQO8BZwEjAWeMbOX3b0iznlLppifvxRQ2lcEjIh4Ppzg18u+btOdRFUeMzsM+D1wmruXJihv8RJNmWcAD4TBZBBwupk1uPvfE5LD2Iv2u13i7tVAtZm9BEwFumNAiaa8FwE/86BzYbWZrQMmAQsTk8WkiPn5S01e7XsdGG9mY8wsG5gHPNZqm8eA88PREkcDO919S6IzGkOdltnMRgIPA5/vpr9WW+u0zO4+xt1Hu/to4K/Al7txMIHovtuPAseZWZaZ9QKOAt5NcD5jJZrybiSojWFmg4GJwNqE5jLxYn7+Ug2lHe7eYGZXAk8RjBL5g7u/Y2aXhet/QzDi53RgNbCL4FdOtxVlmb8LDARuC3+xN3g3nqk1yjKnlGjK7O7vmtm/gKVAE/B7d29z+GlXF+Vn/CPgLjNbRtAUdK27d+sp7c3sfuBEYJCZFQHfA3pA/M5fmnpFRERiQk1eIiISEwooIiISEwooIiISEwooIiISEwooIiISEwooIvvIzAaGs/C+ZWZbzez9cHmHmS2Pw+t938y+vo/7VLWTflcqzJYsXZMCisg+cvdSd5/m7tMI5ve6KVyeRnDNRofMTNd/SUpSQBGJrUwz+114T42nzawnQDjJ4k/C+4r8l5lNN7MXw4kXn2qe5dXMrjKz5eH9KR6IOO7k8Bhrzeyq5kQz+5qZvR0+vto6M+FV0L8Kj/kEUBjf4ks60y8lkdgaD3zG3b9oZg8BZwN/Ctf1c/cTzKwH8CJwprsXm9mngRuAi4FvAWPcvdbM+kUcdxIwC8gHVpjZ7cBhBFc3H0VwdfdrZvaiu78Zsd8nCKYR+RAwmOAeJ3+IR8FFFFBEYmudu78VLi8GRkesezD8OxE4lGBGWwimA2meQ2kpcJ+Z/R34e8S+T7h7LVBrZtsJgsOxwCPhBI6Y2cPAcUBkQDkeuN/dG4HNZvb8gRdRpG0KKCKxVRux3Egw9Xuz6vCvAe+4+zFt7P9RgiBwBvAdM5vSznGzaHv68bZofiVJCPWhiCTeCqDAzI4BMLMeZjbFzDKAEe7+b+CbBLfh7d3BcV4CzjKzXmaWR9C89XIb28wzs8ywn2ZWjMsi0kI1FJEEc/e6cOjuLWbWl+D/8JcE9xr5U5hmBKPHdrR3Uy93f8PM7uKDe3b8vlX/CcAjBDeNWhYe/8UYF0ekhWYbFhGRmFCTl4iIxIQCioiIxIQCioiIxIQCioiIxIQCioiIxIQCioiIxIQCioiIxMT/A4Bk8+4VVxImAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.16\n",
      "Optimal profit: 1280.00 euros\n"
     ]
    }
   ],
   "source": [
    "best_threshold.profit_maximization(model=log_reg_cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on usefulness model:**\n",
    "\n",
    "As we lowered the threshold compared to the original model (0.5 to 0.24), we are extremely positive in assessing people's willigness to subscribe. Specifically, if the predicted probability of someone subscribing to the deposit is greater than 0.24 this person is assigned a positive label (\"yes\"). This will increase the true positive rate (e.g. recall) but also the number of false positives. This model is useful in maximing profitability because it factors in the tradeoff between the cost of false positives (calling a customer without them subscribing), false negatives (oppurtunity costs of missed customer) and true positive (the yield of correctly predicting that a customer will subscribe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.5 (5 points)\n",
    "\n",
    "Now train a random forest model, with 10 decision trees and max_depth=2, what is the profit that can be achieved given the threshold that you identified earlier? Do you need to increase or decrese the threshold to maximize the profit using random forest model? Explain your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing features\n",
    "train_y_rf = train_data[\"y\"]\n",
    "test_y_rf = le.transform(test_data[\"y\"])\n",
    "banking_prepared_rf = preprocessor2.transform(train_data)\n",
    "test_prepared_rf = preprocessor2.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold 0.16, the profit than can be achieved according to the Random Forest model is 1030\n"
     ]
    }
   ],
   "source": [
    "# training random forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=42)\n",
    "rf_clf.fit(banking_prepared_rf, train_y_rf)\n",
    "\n",
    "#probabilties of positive class\n",
    "probabilities = rf_clf.predict_proba(test_prepared_rf)[:,1]\n",
    "\n",
    "# computing predicted labels based on the threshold\n",
    "test_pred_thresh_rf = (probabilities >= 0.16).astype(int)\n",
    "\n",
    "cm_rf = metrics.confusion_matrix(test_y_rf, test_pred_thresh_rf)\n",
    "\n",
    "tp_rf = cm_rf[1, 1]\n",
    "fp_rf = cm_rf[0, 1]\n",
    "\n",
    "profit_rf_class = Profit()\n",
    "profit_rf = profit_rf_class.profit_calc(tp_rf,fp_rf)\n",
    "\n",
    "print(f\"For threshold 0.16, the profit than can be achieved according to the Random Forest model is {profit_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.14\n",
      "Optimal profit: 1250.00 euros\n"
     ]
    }
   ],
   "source": [
    "#use the method defined in the previous question to determine the threhsold for the maximizing profit\n",
    "profit_rf = profit_rf_class.profit_maximization(model=rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation results:**\n",
    "\n",
    "Relative to the profit maximizing threshold of the Logistic Model (0.16), we need to decrease the threshold in the Random Forest classifier (to 0.14) in order to achieve a maximum profit. This implies that the Random Forest model is more conservative in its predictions of positive instances. Specifically, it assigned lower probabilities of \"True\" (or subscribe) compared to the Logistic Model and therefore we had to lower the threshold to maximize the profit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
